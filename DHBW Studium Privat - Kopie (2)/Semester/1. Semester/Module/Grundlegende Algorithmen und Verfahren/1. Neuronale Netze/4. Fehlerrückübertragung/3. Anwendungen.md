1. **NETtalk**:
	- **Sejnowski** und **Rosenberg** **1986**:
		- **Backpropagation Netz**, welches **englische Texte** aus einer **Datei** verständlich **vorlesen konnte**
		- Die **Eingabeschicht** besteht aus $7 \times 29 = 203$ **Neuronen**. Dafür **3 Neuronen** für die **3 Buchstaben** **vor dem aktuellen Zeichen** und **3 danach** Das für **29 Zeichen** (Buchstaben)
		- Darauf folgt eine **verdeckte Schicht mit 80 Neuronen** und eine **Ausgabeschicht** mit **26 Neuronen**. Jedes **Ausgabeneuron** steht für einen **Laut**.
		- Das **Netz** wurde an **1024 Wörtern trainiert**.

2. **Sekundärstruktur von Proteinen**:
	- **Quian** und **Sejnowski** **1988**:
		- //Work in Progress